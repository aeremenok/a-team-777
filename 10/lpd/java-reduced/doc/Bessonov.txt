Синтаксический и лексический анализатор

Одной из неотделимых частей компилятора являются лексический и синтаксический анализаторы.

Лексический анализатор — это программа или часть программы, выполняющая лексический анализ. 
Лексический анализатор обычно работает в две стадии: сканирование и оценка.
На первой стадии, сканировании, лексический анализатор обычно реализуется в виде конечного автомата, 
определяемого регулярными выражениями. В нём кодируется информация о возможных последовательностях символов, 
которые могут встречаться в токенах . 
Во многих случаях первый непробельный символ может использоваться для определения типа следующего токена, 
после чего входные символы обрабатываются один за другим пока не встретится символ, не входящий во множество 
допустимых символов для данного токена. В некоторых языках правила разбора лексем несколько более сложные и 
требуют возвратов назад по читаемой последовательности.
Полученный таким образом токен содержит необработанный исходный текст (строку). 
Для того чтобы получить токен со значением, соответствующим типу (напр. целое или дробное число), 
выполняется оценка этой строки — проход по символам и вычисление значения.

Токен с типом и соответственно подготовленным значением передается на вход синтаксического анализатора.

Синтаксический анализ (парсинг) — это процесс анализа входной последовательности символов, 
с целью разбора грамматической структуры, обычно в соответствии с заданной формальной грамматикой. 
При парсинге исходный текст преобразуется в структуру данных, обычно — в дерево, 
которое отражает синтаксическую структуру входной последовательности и хорошо подходит для дальнейшей обработки.
Обычно синтаксический анализ делится на два уровня:
лексический анализ — входной поток символов («букв») разбивается на линейную последовательность токенов (или так называемых лексем) — «слов» языка;
грамматический анализ — из токенов выделяются «предложения» языка, согласно грамматическим правилам, и создается дерево разбора.

Задача получения лексического и синтаксического анализатора широка распростронена во многих областях, и является часто
встречаемой подзадачей. Например при написание компиляторов, конвертеров, программ экспорта и т.д.
Для быстроты и удобства специально применяются специальные программы, называемые генераторами компиляторов, 
чтобы основдодить программиста от болього количества муторной работы. 

Для нашего случая был выбран генератор компиляторов CoCo/R. Он воспринимает на входе LL(1) грамматику 
и генерирует по ней файлы кода для лексического и синтаксического анализаторов. Для нашего случая был выбран 
CoCo/R генерирующий Java код, потому что наш компилятор написан на этом языке.

При написании грамматики выяснилось, что она не является LL(1) грамматикой в общем случае. Проанализировав
дальше состав нашей бригады пришел к выводу, что граммматика для описываемого нами языка может быть описанна,
как LL(2) грамматика, причем заглядование за символ вперед необходимо совсем не в многих случаях.
Было принято решение использовать CoCo/R и была написанна функция заглядования за следующий символ:
// Функция возвращает токен, следующий за текущим (заглядывает вперед)
boolean next(int i)
	{
		scanner.ResetPeek();
		Token peek = scanner.Peek();
		return (peek.kind == i);
	}
Эта функция напримую вставляется в код генерируемого синтаксического анализатора. Особенностью использования
это функции является следующее: она проверяет соответствует ли токен идущий за следующим ожидаемому. CoCo/R 
номерует все встречающиеся токены, а для токенов описанных в соответсвующем раздели создает синонимы, которые
начинаются с подчеркивания:
Участок файла грамматики:
TOKENS
	identifier  = letter { letter | digit }. // любое слово 
	realNumber =             ['-']  [digit { digit }  dot]  digit { digit } ["e-" digit {digit}] . // Действительное число
	string = '"' {stringCh} '"'. // Строка, ограниченная двойными кавычками
	interface =		"interface".
	final=			"final".
	static =		"static".
Участок файла генерируемого кода
enum {
		_EOF=0,
		_identifier=1,
		_realNumber=2,
		_string=3,
		_interface=4,
		_final=5,
		_static=6,
...}
Так вот чтобы использовать функцию next надо явно задать токен и в файле грамматики написать 
следующую конструкцию:
IF(next(_identifier))